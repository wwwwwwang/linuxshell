#path
etl.path=/opt/etl
bdr-command-bootstrap.path=/opt/bdr-command-bootstrap
log-collector.path=/opt/log-collector
file-watcher.path=/opt/file-watcher
log-save-server.path=/opt/log-save-server
oozie-java-client.path=/opt/oozie-java-client
sqoop_web.path=/opt/sqoop_web
ml.path=/opt/ml

#mysql 
db.mysql.url=jdbc:mysql://172.31.18.67:3306/edmp?autoReconnect=true\&useSSL=false\&useUnicode=true\&characterEncoding=utf-8
db.mysql.user=edmp
db.mysql.password=Edmp@1234

#oozie
oozie=http://172.31.18.13:11000/oozie
nameNode=hdfs://nameservice1
jobTracker=yarnRM
host=172.31.18.14
hostName=hadoop104.dategeek.com.cn

#bdr-command-bootstrap  conf/conn.properties
flume.pubsub.port=65113
flume.program.path=/etc/flume-ng

#log-collector conf/conn.properties  mysql
db.mysql.agent.name=server1
#sender target. kafka or flume
sender.target=flume
#采集业务日志使用1，系统日志使用0，1表示应答方式，0表示无应答方式
generaludp.receiver.replyOrNo=0
#kafka.producer.sender.partition=8
log.kafka.broker.list=172.31.18.12:9092,172.31.18.13:9092,172.31.18.14:9092
#avato.logs表示是否使用文件上传功能，其值只能为"csv"或是空串
#其中csv表示使用文件上传功能，后面的3个参数会生效；
#如是空串表示不是文件上传功能，后面3个参数没有作用
avato.logs=
avato.csv.file.path=/data0/log-splitter/data
avato.csv.hdfs.path=hdfs://nameservice1/avato
avato.csv.db.name=wuxibank

#logSaveServer config/conn.properties  mysql
kafka.zookeeper=172.31.18.12:2181,172.31.18.13:2181,172.31.18.14:2181

#etl config/mysql.properties myql
mapreduce.jobtracker.ip=172.31.18.11
yarn.resourcemanager.ip=172.31.18.10
db.hbase.zookeeper_quorm=hadoop102.dategeek.com.cn,hadoop103.dategeek.com.cn

#oozieJavaClient  config/conn.properties mysql

#file-watcher config/conn.properties mysql 
################config/filewatcher.properties needs to be changed manually############

#sqoop-web  config/conn.properties myql
subscriber.command.port=65112
hive.metastore.uris=thrift://hadoop101.dategeek.com.cn:9083
